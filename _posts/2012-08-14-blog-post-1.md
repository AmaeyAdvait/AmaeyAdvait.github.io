---
title: 'NeuroAI'
date: 2025-11-25
permalink: /posts/2025/11/NeuroAI/
tags:
  - cool posts
  - category1
  - category2
---


"If you want to understand the world, you have to start by understanding - truly understanding - how we experience it." <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*~Helena Smith, Recursion(Blake Crouch)*

---

***This blog post is designed to give a pithy perspective into the fascinating world of NeuroAI and what it specifically means to me.***

*"What is your earliest memory?"*

<br>
I start the journey here, purely because it is a question we all have retrospectively wondered about at some point in our lives. It's definitely a curious topic to ponder upon and the point I'm trying to delve further into, is this: how much of the memory we can remember, and more precisely, how do we remember it?

Most of us try to visualise it in unique, often self referential ways. Objects, emotions, the quaint feeling of an identity. It's a wonderful perceptual keyhole to peep through some of the most challenging problems we wish to solve, simply because it internalizes a powerful quality seen across all minds of innovation: **Self Credible Curiosity.**

<br>
Ok, I know I just dropped three relatively heavy words with little context, but we'll circle back to them throughout this post. In the meantime, time to shift gears. 

As an introspective engineer, I stongly believe in building systems that have a strong foundation, robust framework and a clear application. NeuroAI is a bridge between mind and machine that can help achieve exactly that. Let me illustrate via an example:-

---

A Visual Thought Experiment
===========================

a) *<u>Benchmark</u>: "Consider two people(Alice and Bob) sitting in two different rooms. Both are given k bits of information regarding a particular (static) scene and are asked to visualise the same in their minds. What is the minimum threshold value k beyond which the probability that they visualise different scenes drops below {% raw %}$$\epsilon$${% endraw %} = 0.01?"*

An important point to note here is the infinitely large array of attributes that can define a particular scene. For example, when asked to visualise a ball, some defining attributes that come to mind are:- <br>
1) Colour(blue, gree, red etc.) <br>
2) Diameter(5cm, 10m, 20km etc.) <br>
3) Material(rubber, plastic, cork etc.) <br>
4) Background(cricket ground, beach, pure white etc.) <br>

 and so on.

 <br>
Consider 'n' discrete attributes. For simplicity, let us assume that every attribute in the set is an independent and identically distributed random variable with finite precision. This is a gross approximation, but in most cases it can atleast serve as a sufficient decision boundary.

<br>
Information theory gives us the insight to approach this problem. As a simplified problem, we consider:- <br>
1) Colour: A 24 bit RGB <br>
2) Diameter: If the threshold is set between 5 and 25 cm, with a precision of 0.1 cm, we get:-
   <p>{% raw %}$$log_2((25-5)/0.1) = log_2(200) = 8 bits(rounded)$${% endraw %}</p>

3) Material: Consider an array of 128 possible materials for a ball:-
   <p>{% raw %}$$log_2(128) = 7 bits$${% endraw %}</p>

4) Background: Consider a background of 1000x1000 pixels:-
   <p>{% raw %}$$log_2(10^6) = 20 bits(rounded)$${% endraw %}</p>

Hence, the total number of bits(bits<sub>total1</sub>) required is 59 bits, or in the range of {% raw %}$$[40,80]$${% endraw %} bits on average.

Now denote the time taken for information flow from the experimenters to Alice and Bob as t<sub>i</sub>. This is a constant value for this iteration (benchmark) and subsequent iterations, so it can be ignored to compare relative time differences.

However, the time taken to reach convergence (denoted by t<sub>c</sub>) is quite high, since for each bit, creating a mental image(cortical processing) takes around 20 milliseconds on average. <br><br>
Reference: [Efficient Coding Hypothesis: Possible Principles Underlying the Transformations of Sensory Messages by Barlow et al., 1961](https://www.cnbc.cmu.edu/~tai/microns_papers/Barlow-SensoryCommunication-1961.pdf)

Hence, t<sub>total1</sub> = t<sub>c1</sub>(around [1,1.5] seconds) + t<sub>i</sub>

**---**

b) *"<u>Test</u>: Now consider Alice and a rudimentary computer vision model named Bob sitting in two different rooms. Both are given k bits of information regarding a particular (static) scene and are asked to visualise the same in their minds. What is the minimum threshold value k beyond which the probability that they visualise different scenes drops below {% raw %}$$\epsilon$${% endraw %} = 0.01?"*

In this situation, we try to calculate the joint convergence threshold. A major drawback that we immediately see here is the mismatch of priors between the mind and the machine. There is no way to prove that given the same attributes, both will necessarily converge after a certain number of bits, because the world models used by both are vastly different. 

Assuming that there is a linear dependency between the mismatch of priors and t<sub>c2</sub> and that they do manage to converge:-

bits<sub>total2</sub> = {% raw %}$$59  + 59*n = 59*5 = 295 bits = [250,500] bits$${% endraw %} (for 4 attributes)

Since the information processing power of the machine is much higher:-

t<sub>total2</sub> - t<sub>i</sub> = {% raw %}$$10(\mu)s*59 = [0.5,1]ms $${% endraw %}

So we see a huge tradeoff in the number of bits required v/s latency of information flow. The bit tradeoff seems negligible compared to the latency tradeoff at present but for large n, they are comparable.

**---**

c) *"<u>Improve</u>: Now consider Alice and a neuroAI model named Bob sitting in two different rooms. Both are given k bits of information regarding a particular (static) scene and are asked to visualise the same in their minds. What is the minimum threshold value k beyond which the probability that they visualise different scenes drops below {% raw %}$$\epsilon$${% endraw %} = 0.01?"*

The idea is to observe how integration could vastly reduce the mismatch of priors while improving latency of the benchmark. In this case:-

bits<sub>total3</sub> = {% raw %}$$[100, 200] bits$${% endraw %}

t<sub>total2</sub> - t<sub>i</sub> = {% raw %}$$[50,500]ms$${% endraw %}

Of course, these numbers mentioned above are strictly hypothetical and the notion of what a neuroAI model could do is still in its very nasent stages. Some discussion on this follows below.

---










------

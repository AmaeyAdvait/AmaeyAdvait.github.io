---
title: 'Cognitive Robotics'
date: 2025-11-26
permalink: /posts/2025/11/cognitive_robotics/
tags:
  - cool posts
  - category1
  - category2
---

"The human brain is, after all, the best example we have of an intelligent system. If we can learn its methods, we can use these biologically inspired paradigms to build more intelligent machines."                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*~Von Neumann, The Computer and the Brain*

---

***This blog post is designed to give a pithy perspective into the fascinating world of Cognitive Robotics and what it specifically means to me.***

NeuroAI Systems (Part 2)
========================

Feedback. 

It's a ubiquitous term. It's also understandingly very powerful in circuits and control, but what makes it so?

I had the wonderful opportunity to experiment in the analog circuits lab in my third semester. My first experience in feedback actually occured just over a month ago in the same lab. Two weeks prior to that day, I had burnt my hand(only slightly) when my lab partner and I were tinkering with a CL100 transistor in the process of building an audio amplifier. At the end of that lab, our oscilloscope showed the same dreaded noisy sine wave, with no tangible output emnating from the speaker. 

It felt excruciatingly tiring, knowing every time entering the lab that there will be some deviation from the expected results. I couldn't understnad why somebody hadn't come up with a tangible solution. So imagine my surprise when we were successfully able to design an RC phase shift oscillator in under two hours during the next lab! The output was exceptionally table and the target frequency was exactly what we had calculated it to be.

From the perspective of an introspective engineer, it made me curious as to why negative feedback has such a drastic impact on the stability of a signal. Why does repeatedly subtracting a portion of the output from the input give us a much better output?

Some properties of negative feedback that help it achieve stability are gain desensitization, bandwisth extension, modification of input-output impedances and higher linearity. But the true error reduction lies in its sensing and return mechanisms. 

It's really simple to break down cognitive robotics into two feedback circuits: Physical and Cognitive. On one side, sensors essentially detect not just the input signals, but also the result of the actuator's feedback to it, thus enabling the robots to learn from its own mistakes in the physical world. The Cognitive feedback loop is reinforcement learning, which enables the robots to learn from its own mistakes in its decision making.

---

A Strategic Thought Experiment
==============================

As a passionate chess player who has played the sport for more than a decade now, I cannot deny the enormous change that chess engines have brought into the landscape. It's fascinating to see many chess engines like Stockfish used daily by many professional and rising players in the chess community. 

In the last decade, advances by Google DeepMind and some other research labs using self reinforcement learning have managed to solve many of the 2 player games. Further, researchers have been able to create not just narrow but also general proficiency in such scenarios. However, in recent years, there is one other variant of chess that has begun to gain traction. In accordance with the same, consider the following scenario:-

*"<u>FFA[Free For All]4 Player Chess</u>: Multi agent systems are quickly improving in the perspective of creating simulated worlds incorporating vision, sound and other senses. However, very few of them currently focus on improving intelligence in the simulated world, which is crucial in understanding how to simulate the brain. To do this requires some insights from game theory, and 4 player chess is a great example. How could one go about designing an engine that optimizes for a single agent's success? Is it also create a 4 player chess puzzle solver to solve puzzles like the one attached below(Basically, can the starting position of analysis be variable)?"*

![4 player Chess: Red to move and Win](https://github.com/AmaeyAdvait/AmaeyAdvait.github.io/blob/master/_posts/4pc.jpg?raw=true)

<br>
The key point to realise is that brains, engines and ultimately cognitive robots all predict, make errors and then correct them when the future predictions fail. This shows that one key component that we can carry over from 2 player games to multi player games/worlds is feedback, only that in the case of more agents, we can use cascaded feedback models to understand every agent's amiability towards forming mutual alliances and deeper intent. 

So the cognitive feedback loop for 4 player chess can be designed as (prediction -> p):-

p<sub>t+1</sub>(i) = p<sub>t</sub>(i) - {% raw %}$$\eta$${% endraw %}*p_error<sub>t</sub>(i,j) for every i,j = 1,2,3,4

Here, p_error could be a threatmap, a collection of various different parameters weighted to give an adaptive score to each of the other agents relative to itself(normalised as unity).This takes into account the agent's self model along with its cognizance of other agent's models. For example, if blue were to constantly attack your king, it shows that blue has a certian level of hostility towards you and might have formed mutual alliances with other agents to attack your king.

The engine then creates a selective attention vector towards each agent and chooses the move that minimizes the expected joint prediction error of vector with an internal strategy function. However, defining an optimal strategy here might not be as straightforward as it seems.

Of course, I have only scratched the surface of the topic in this blog. For example, you may observe that I've assumed all agents are level-1 players (k-level reasoning). This is certainly not true as the strength of play increases. However, expanding it requires game theory equilibria concepts that I have not studied and I definitely do not want to claim otherwise. I'm not even sure that feedback models will not be able to give an accurate picture of the complicated strategies underlying the logic in such circumstances.

This is a long term project which I'm looking to study deeper, understand and hopefully implement over an year or two. Looking forward to learning more about it!

---





